#!/usr/bin/env python3
"""AI ì„œë¹„ìŠ¤ ì§ì ‘ í…ŒìŠ¤íŠ¸"""

import json
import sys
import os
from unittest.mock import patch, Mock

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(__file__))

def test_ai_service_mock():
    """Mockì„ ì‚¬ìš©í•œ AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    print("=== Mock AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ===")
    
    # AI ì„œë¹„ìŠ¤ Mock í…ŒìŠ¤íŠ¸
    from src.handlers.create_inquiry import generate_ai_response
    
    test_inquiry = {
        'title': 'AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸',
        'content': 'ì´ê²ƒì€ AI ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.',
        'category': 'general',
        'urgency': 'medium'
    }
    
    # Mock AI ì‘ë‹µ
    mock_response = "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì˜í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ë¬¸ì˜ì— ëŒ€í•´ ë‹µë³€ë“œë¦½ë‹ˆë‹¤."
    
    with patch('src.handlers.create_inquiry.generate_ai_response', return_value=mock_response):
        try:
            response = generate_ai_response(test_inquiry)
            print(f"âœ… AI ì‘ë‹µ ìƒì„± ì„±ê³µ: {response[:50]}...")
            return True
        except Exception as e:
            print(f"âŒ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return False

def test_bedrock_connection():
    """Bedrock ì—°ê²° í…ŒìŠ¤íŠ¸"""
    
    print("\n=== Bedrock ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
    
    try:
        import boto3
        
        # Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­
        test_prompt = "ì•ˆë…•í•˜ì„¸ìš”"
        
        # Claude 3.5 Sonnet ëª¨ë¸ ì‚¬ìš©
        model_id = "anthropic.claude-3-5-sonnet-20241022-v2:0"
        
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 100,
            "messages": [
                {
                    "role": "user",
                    "content": test_prompt
                }
            ]
        }
        
        print(f"ëª¨ë¸ ID: {model_id}")
        print(f"ìš”ì²­ ë‚´ìš©: {test_prompt}")
        
        response = bedrock.invoke_model(
            modelId=model_id,
            body=json.dumps(request_body)
        )
        
        response_body = json.loads(response['body'].read())
        ai_response = response_body['content'][0]['text']
        
        print(f"âœ… Bedrock ì—°ê²° ì„±ê³µ")
        print(f"AI ì‘ë‹µ: {ai_response}")
        return True
        
    except Exception as e:
        print(f"âŒ Bedrock ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        print("   - AWS ìê²© ì¦ëª… í™•ì¸ í•„ìš”")
        print("   - Bedrock ì„œë¹„ìŠ¤ ê¶Œí•œ í™•ì¸ í•„ìš”")
        print("   - ëª¨ë¸ ì•¡ì„¸ìŠ¤ ê¶Œí•œ í™•ì¸ í•„ìš”")
        return False

def test_lambda_ai_service():
    """Lambda í™˜ê²½ì—ì„œ AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
    
    print("\n=== Lambda AI ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ===")
    
    # Lambda í™˜ê²½ë³€ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
    os.environ['AWS_REGION'] = 'us-east-1'
    os.environ['BEDROCK_DEFAULT_MODEL'] = 'anthropic.claude-3-5-sonnet-20241022-v2:0'
    
    try:
        # AI ì„œë¹„ìŠ¤ import ì‹œë„
        from src.services.ai_service import AIService
        
        ai_service = AIService()
        
        test_inquiry = {
            'title': 'Lambda í…ŒìŠ¤íŠ¸',
            'content': 'Lambda í™˜ê²½ì—ì„œ AI ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸',
            'category': 'general',
            'urgency': 'medium'
        }
        
        # Mock Bedrock ì‘ë‹µ
        mock_bedrock_response = {
            'body': Mock()
        }
        mock_bedrock_response['body'].read.return_value = json.dumps({
            'content': [{'text': 'Lambda í™˜ê²½ì—ì„œ AI ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.'}]
        }).encode()
        
        with patch.object(ai_service.bedrock, 'invoke_model', return_value=mock_bedrock_response):
            response = ai_service.generate_response(test_inquiry)
            print(f"âœ… Lambda AI ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ")
            print(f"ì‘ë‹µ: {response}")
            return True
            
    except ImportError as e:
        print(f"âŒ AI ì„œë¹„ìŠ¤ import ì‹¤íŒ¨: {str(e)}")
        print("   - config.ai_models ëª¨ë“ˆ ë¬¸ì œ")
        return False
    except Exception as e:
        print(f"âŒ Lambda AI ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
        return False

if __name__ == '__main__':
    print("ğŸ§ª AI ì„œë¹„ìŠ¤ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    results = []
    
    # 1. Mock í…ŒìŠ¤íŠ¸
    results.append(test_ai_service_mock())
    
    # 2. Bedrock ì—°ê²° í…ŒìŠ¤íŠ¸ (ì‹¤ì œ AWS í˜¸ì¶œ)
    results.append(test_bedrock_connection())
    
    # 3. Lambda ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
    results.append(test_lambda_ai_service())
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"ì„±ê³µ: {sum(results)}/{len(results)}")
    
    if all(results):
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ - AI ì„œë¹„ìŠ¤ ì •ìƒ")
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - AI ì„œë¹„ìŠ¤ ë¬¸ì œ ìˆìŒ")
        print("\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. AWS ìê²© ì¦ëª… ì„¤ì • í™•ì¸")
        print("2. Bedrock ì„œë¹„ìŠ¤ ê¶Œí•œ í™•ì¸")
        print("3. ëª¨ë¸ ì•¡ì„¸ìŠ¤ ê¶Œí•œ í™•ì¸")
        print("4. Lambda í•¨ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸")
