#!/usr/bin/env python3
"""
ğŸ” Bedrock ì—°ë™ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ëª¨ë¸ IDì™€ ê¶Œí•œ ë¬¸ì œ í™•ì¸
"""
import boto3
import json
import sys
import os

# config ëª¨ë“ˆ import
sys.path.append('.')
from config.ai_models import ai_model_config

def check_bedrock_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Bedrock ëª¨ë¸ í™•ì¸"""
    print("ğŸ” Bedrock ëª¨ë¸ í™•ì¸")
    print("=" * 50)
    
    try:
        bedrock = boto3.client('bedrock', region_name='us-east-1')
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        response = bedrock.list_foundation_models()
        
        print("âœ… ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸:")
        claude_models = []
        for model in response['modelSummaries']:
            if 'claude' in model['modelId'].lower():
                claude_models.append(model)
                print(f"  - {model['modelId']} ({model['modelName']})")
        
        return claude_models
        
    except Exception as e:
        print(f"âŒ Bedrock ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return []

def test_bedrock_invoke():
    """ì‹¤ì œ Bedrock ëª¨ë¸ í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Bedrock ëª¨ë¸ í˜¸ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸ IDë“¤
    test_models = [
        "anthropic.claude-3-5-sonnet-20241022-v2:0",
        "anthropic.claude-3-sonnet-20240229-v1:0", 
        "anthropic.claude-3-haiku-20240307-v1:0",
        "anthropic.claude-3-opus-20240229-v1:0"
    ]
    
    bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')
    
    for model_id in test_models:
        print(f"\ní…ŒìŠ¤íŠ¸ ëª¨ë¸: {model_id}")
        try:
            body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 100,
                "temperature": 0.7,
                "messages": [
                    {
                        "role": "user",
                        "content": "ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
                    }
                ]
            }
            
            response = bedrock_runtime.invoke_model(
                modelId=model_id,
                body=json.dumps(body)
            )
            
            response_body = json.loads(response['body'].read())
            ai_response = response_body['content'][0]['text']
            
            print(f"âœ… ì„±ê³µ: {ai_response[:50]}...")
            
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {str(e)}")

def check_current_config():
    """í˜„ì¬ AI ëª¨ë¸ ì„¤ì • í™•ì¸"""
    print("\nâš™ï¸ í˜„ì¬ AI ëª¨ë¸ ì„¤ì •")
    print("=" * 50)
    
    config = ai_model_config.config
    
    for key, value in config.items():
        print(f"{key}: {value}")
    
    print(f"\nğŸ¯ ì„ íƒëœ ëª¨ë¸ ì˜ˆì‹œ:")
    print(f"ê°„ë‹¨í•œ ìš”ì²­: {ai_model_config.get_model_for_request('simple', 'normal')}")
    print(f"ë³µì¡í•œ ìš”ì²­: {ai_model_config.get_model_for_request('complex', 'normal')}")
    print(f"ë†’ì€ ìš°ì„ ìˆœìœ„: {ai_model_config.get_model_for_request('medium', 'high')}")

def suggest_fixes():
    """ë¬¸ì œ í•´ê²° ë°©ì•ˆ ì œì‹œ"""
    print("\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ì•ˆ")
    print("=" * 50)
    print("""
1. ëª¨ë¸ ID ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš°:
   - config/ai_models.pyì—ì„œ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ IDë¡œ ë³€ê²½
   - CDK ìŠ¤íƒì˜ í™˜ê²½ë³€ìˆ˜ë„ í•¨ê»˜ ì—…ë°ì´íŠ¸

2. ê¶Œí•œ ë¬¸ì œì¸ ê²½ìš°:
   - AWS Console â†’ Bedrock â†’ Model access í™•ì¸
   - í•„ìš”í•œ Claude ëª¨ë¸ë“¤ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
   - IAM ì—­í• ì— bedrock:InvokeModel ê¶Œí•œ í™•ì¸

3. í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ë°©ë²•:
   - infra/stacks/api_stack.py ìˆ˜ì •
   - ./deploy.sh api ì¬ë°°í¬

4. ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ë°©ë²•:
   - python3 debug_bedrock.py ì‹¤í–‰
   - CloudWatch ë¡œê·¸ í™•ì¸
""")

if __name__ == "__main__":
    print("ğŸ” Bedrock ì—°ë™ ë””ë²„ê¹…")
    print("=" * 50)
    
    # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = check_bedrock_models()
    
    # 2. í˜„ì¬ ì„¤ì • í™•ì¸
    check_current_config()
    
    # 3. ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
    test_bedrock_invoke()
    
    # 4. í•´ê²° ë°©ì•ˆ ì œì‹œ
    suggest_fixes()